{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task2_code",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3mq3t_J6tAS",
        "outputId": "5bbad029-0c3e-4a2e-9598-95b3f7186a70"
      },
      "source": [
        "!pip install python-levenshtein"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein) (50.3.2)\n",
            "Building wheels for collected packages: python-levenshtein\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144794 sha256=8475090836418b86f654804cbed497daa72b1cb4b596236e9be5213797a625c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-levenshtein\n",
            "Installing collected packages: python-levenshtein\n",
            "Successfully installed python-levenshtein-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tikHxUxV0huC"
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pdb\n",
        "import string\n",
        "from Levenshtein import distance\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMBK9d_z0jMJ"
      },
      "source": [
        "def wav2feat(wavfile):\n",
        "    '''\n",
        "    Input: audio wav file name\n",
        "    Output: Magnitude spectrogram\n",
        "    '''\n",
        "    x, Fs = librosa.load(wavfile, sr=44100, mono=True) \n",
        "    hop = int(0.01 * Fs) # 10ms\n",
        "    win = int(0.02 * Fs) # 20ms\n",
        "    X = librosa.stft(x, n_fft=1024, hop_length=hop, win_length=win, window='hann', center=True, pad_mode='reflect')\n",
        "    return np.abs(X)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djbTFHPp0uNZ"
      },
      "source": [
        "def read_csv(filename):\n",
        "    id_label = {}\n",
        "    with open(filename,'r') as fid:\n",
        "        for line in fid: # '176787-5-0-27.wav,engine_idling\\n'\n",
        "            tokens = line.strip().split(',') # ['176787-5-0-27.wav', 'engine_idling']\n",
        "            id_label[tokens[0]] = tokens[1]\n",
        "    return id_label"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLGnnNAX6m6x"
      },
      "source": [
        "def editDistance(gt, est):\n",
        "    '''both are lists of labels\n",
        "    E.g. gt is \"dog_bark-street_music-engine_idling\"\n",
        "    E.g. est is \"street_music-engine_idling\"\n",
        "    '''\n",
        "    gttokens = gt.split('-')\n",
        "    esttokens = est.split('-')\n",
        "    # Map token to char\n",
        "    tokenset = list(set(gttokens+esttokens)) # ['dog_bark', 'siren', 'street_music', 'engine_idling']\n",
        "    token_char = {}\n",
        "    for i in range(len(tokenset)):\n",
        "        token_char[tokenset[i]] = string.ascii_uppercase[i]  # {'dog_bark': 'A', 'siren': 'B', 'street_music': 'C', 'engine_idling': 'D'}\n",
        "    # convert gt and est to strings\n",
        "    gtstr = [token_char[t] for t in gttokens]\n",
        "    gtstr = ''.join(gtstr)  # 'BCA'\n",
        "    eststr = [token_char[t] for t in esttokens]\n",
        "    eststr = ''.join(eststr)  # \n",
        "    # Compare\n",
        "    editdist = distance(gtstr, eststr) # 1\n",
        "    score = 1 - editdist/len(gtstr)\n",
        "    return editdist, score"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMFwQuqkdhqZ"
      },
      "source": [
        "def unique_class(y):\n",
        "  #unique class\n",
        "  cl=np.unique(y)\n",
        "  num_cl=len(cl)\n",
        "  return cl,num_cl"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3prEEq-Odilu"
      },
      "source": [
        "#one hot encoding\n",
        "def one_hot_encoding(y_tr,y_te):\n",
        "  cl,num_cl=unique_class(y_tr)\n",
        "  y_train=np.zeros((len(y_te),num_cl))\n",
        "  for i in range(0,len(y_te)):\n",
        "    for j in range(0,num_cl):\n",
        "      if y_te[i]==cl[j]:\n",
        "        y_train[i][j]=1\n",
        "        break\n",
        "  return y_train"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTGlr3kygTCq"
      },
      "source": [
        "#reshape input data\n",
        "def reshape_X(X):\n",
        "  A=X.shape[0]\n",
        "  B=X[0].shape[0]\n",
        "  C=X[0].shape[1]\n",
        "  X.resize(A,B,C,1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdRw_gc6j7DN"
      },
      "source": [
        "#classname to class number map\n",
        "def class_map(uniq_clas):\n",
        "  d={}\n",
        "  for i in range(0,len(uniq_clas)):\n",
        "    d[i] = uniq_clas[i]\n",
        "  return d"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ep-65UNk9TK"
      },
      "source": [
        "#y_pred num to lable\n",
        "def num_to_lable(y):\n",
        "  lable=[]\n",
        "  for i in y:\n",
        "    lable.append(map[i])\n",
        "  return lable"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSHEycw7lyVy"
      },
      "source": [
        "#write csv file\n",
        "def write_csv(aud_name,lable,filepath): \n",
        "  dict = {'name': aud_name, 'class': lable}      \n",
        "  df = pd.DataFrame(dict)  \n",
        "  df.to_csv(filepath,index=False) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyPkP4v536lV",
        "outputId": "24ee75bc-d071-4294-b96e-dfa51708a09d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc_jtnVx07k8"
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "  f='/content/drive/MyDrive/labels_train.csv'\n",
        "  aud_lable=read_csv(f)\n",
        "  x_train=[]\n",
        "  y=[]\n",
        "  df = pd.read_csv(f, sep=',', header=None)\n",
        "  aud_name = df[0].values\n",
        "  aud_name = aud_name[1:]\n",
        "  for i in aud_name:\n",
        "    w='/content/drive/MyDrive/audio_train_1ch/'+i\n",
        "    U=wav2feat(w)\n",
        "    U.resize(513,401)\n",
        "    x_train.append(U)\n",
        "    y.append(aud_lable[i])\n",
        "  x_train=np.array(x_train)\n",
        "  y=np.array(y)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98p7XRbdLt2T"
      },
      "source": [
        "reshape_X(x_train)\n",
        "cl,num_cl=unique_class(y)\n",
        "y_train=one_hot_encoding(y,y)\n",
        "norm_x=tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True)\n",
        "norm_x.fit(x_train)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "094AvNht-l7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fc8695-29cc-4a27-ae1b-56b8867d8f2c"
      },
      "source": [
        "#Define Model\n",
        "input_shape=x_train[0].shape\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
        "model.add(Convolution2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_cl, activation='softmax'))\n",
        "#Compile\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizers.Adam(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 511, 399, 32)      320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 509, 397, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 254, 198, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 254, 198, 64)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3218688)           0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               411992192 \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 412,012,298\n",
            "Trainable params: 412,012,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um9N4aTyABRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bc0129-eecf-4350-a0aa-be5564a479b9"
      },
      "source": [
        "#Train and Test The Model\n",
        "model.fit(norm_x.flow(x_train, y_train, batch_size=5), steps_per_epoch=len(x_train)/10, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "177/176 [==============================] - 1183s 7s/step - loss: 1.8571 - accuracy: 0.4169\n",
            "Epoch 2/10\n",
            "177/176 [==============================] - 1211s 7s/step - loss: 1.3014 - accuracy: 0.6095\n",
            "Epoch 3/10\n",
            "177/176 [==============================] - 1198s 7s/step - loss: 0.9877 - accuracy: 0.6927\n",
            "Epoch 4/10\n",
            "177/176 [==============================] - 1205s 7s/step - loss: 0.6925 - accuracy: 0.8127\n",
            "Epoch 5/10\n",
            "177/176 [==============================] - 1216s 7s/step - loss: 0.5425 - accuracy: 0.8542\n",
            "Epoch 6/10\n",
            "177/176 [==============================] - 1206s 7s/step - loss: 0.4577 - accuracy: 0.8820\n",
            "Epoch 7/10\n",
            "177/176 [==============================] - 1210s 7s/step - loss: 0.4304 - accuracy: 0.9062\n",
            "Epoch 8/10\n",
            "177/176 [==============================] - 1201s 7s/step - loss: 0.4050 - accuracy: 0.9058\n",
            "Epoch 9/10\n",
            "177/176 [==============================] - 1209s 7s/step - loss: 0.2854 - accuracy: 0.9379\n",
            "Epoch 10/10\n",
            "177/176 [==============================] - 1204s 7s/step - loss: 0.2382 - accuracy: 0.9455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6752556400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weocWCl9KXgX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TWck0u38Df7"
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "  label_task2=[]\n",
        "  f='/content/drive/MyDrive/output/data/data/test_task2/task2.csv'\n",
        "  #aud_lable1=read_csv(f)\n",
        "  test1= pd.read_csv(f, sep=',', header=None)\n",
        "  aud_test1 = test1[0].values\n",
        "  for i in aud_test1:\n",
        "    w='/content/drive/MyDrive/output/data/data/test_task2/feats/'+i\n",
        "    V=np.load(w)\n",
        "    V=np.array(V)\n",
        "    T=V.shape[1]/80\n",
        "    P=int(T)\n",
        "    if (T-P)<0.1:\n",
        "      T=P\n",
        "    else:\n",
        "      T=P+1\n",
        "    W=[]\n",
        "    for i in range(0,T):\n",
        "      H=i*10\n",
        "      Z=V[0:,H:H+401]\n",
        "      if Z.shape[1]<401:\n",
        "        break\n",
        "      W.append(Z)\n",
        "    W=np.array(W)\n",
        "    W.resize(len(W),513,401,1)\n",
        "    #y_test2=one_hot_encoding(y,U)\n",
        "    #scores2 = model.evaluate(Z, y_test2, verbose=1)\n",
        "    ynew2 = model.predict_classes(W)\n",
        "    lab1=num_to_lable(ynew2)\n",
        "    Num=len(lab1)\n",
        "    k=1\n",
        "    while k<Num:\n",
        "      if k==Num:\n",
        "        break\n",
        "      elif lab1[k-1]==lab1[k]:\n",
        "        del lab1[k]\n",
        "        Num=len(lab1)\n",
        "        k=k-1\n",
        "      k=k+1\n",
        "      Num=len(lab1)\n",
        "    s='-'\n",
        "    s = s.join(lab1)\n",
        "    label_task2.append(s)\n",
        "  f_path=f_path='/content/drive/MyDrive/output/task2_labels_test.csv'\n",
        "  write_csv(aud_test1,label_task2,f_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}